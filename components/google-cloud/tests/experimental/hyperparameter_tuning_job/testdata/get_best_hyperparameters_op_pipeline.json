{
  "components": {
    "comp-get-best-hyperparameters": {
      "executorLabel": "exec-get-best-hyperparameters",
      "inputDefinitions": {
        "parameters": {
          "study_spec_metrics": { "parameterType": "LIST" },
          "trials": { "parameterType": "LIST" }
        }
      },
      "outputDefinitions": {
        "parameters": { "output": { "parameterType": "LIST" } }
      }
    }
  },
  "deploymentSpec": {
    "executors": {
      "exec-get-best-hyperparameters": {
        "container": {
          "args": [
            "--trials",
            "{{$.inputs.parameters['trials']}}",
            "--study-spec-metrics",
            "{{$.inputs.parameters['study_spec_metrics']}}",
            "----output-paths",
            "{{$.outputs.parameters['output'].output_file}}"
          ],
          "command": [
            "sh",
            "-c",
            "(PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'google-cloud-aiplatform==1.18.3' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'google-cloud-aiplatform==1.18.3' --user) && \"$0\" \"$@\"",
            "sh",
            "-ec",
            "program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
            "def get_best_hyperparameters(trials, study_spec_metrics):\n  \"\"\"Retrieves the best hyperparameters based on the trials.\n\n  Args:\n      trials (list): Required. List representing the intermediate\n        JSON representation of the trials from the hyperparameter tuning job.\n      study_spec_metrics (list): Required. List serialized from dictionary\n        representing the metrics to optimize.\n        The dictionary key is the metric_id, which is reported by your training\n        job, and the dictionary value is the optimization goal of the metric\n        ('minimize' or 'maximize'). example:\n        metrics = hyperparameter_tuning_job.serialize_metrics(\n            {'loss': 'minimize', 'accuracy': 'maximize'})\n\n  Returns:\n      List representing the intermediate JSON representation of the best\n      hyperparameters from the best trial in the list of trials.\n\n  Raises:\n      RuntimeError: If there are multiple metrics.\n  \"\"\"\n  from google.cloud.aiplatform_v1.types import study\n\n  if len(study_spec_metrics) > 1:\n    raise RuntimeError('Unable to determine best parameters for multi-objective'\n                       ' hyperparameter tuning.')\n  trials_list = [study.Trial.from_json(trial) for trial in trials]\n  best_trial = None\n  goal = study_spec_metrics[0]['goal']\n  best_fn = None\n  if goal == study.StudySpec.MetricSpec.GoalType.MAXIMIZE:\n    best_fn = max\n  elif goal == study.StudySpec.MetricSpec.GoalType.MINIMIZE:\n    best_fn = min\n  best_trial = best_fn(\n      trials_list, key=lambda trial: trial.final_measurement.metrics[0].value)\n\n  return [\n      study.Trial.Parameter.to_json(param) for param in best_trial.parameters\n  ]\n\ndef _serialize_json(obj) -> str:\n    if isinstance(obj, str):\n        return obj\n    import json\n\n    def default_serializer(obj):\n        if hasattr(obj, 'to_struct'):\n            return obj.to_struct()\n        else:\n            raise TypeError(\n                \"Object of type '%s' is not JSON serializable and does not have .to_struct() method.\"\n                % obj.__class__.__name__)\n\n    return json.dumps(obj, default=default_serializer, sort_keys=True)\n\nimport json\nimport argparse\n_parser = argparse.ArgumentParser(prog='Get best hyperparameters', description='Retrieves the best hyperparameters based on the trials.')\n_parser.add_argument(\"--trials\", dest=\"trials\", type=json.loads, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--study-spec-metrics\", dest=\"study_spec_metrics\", type=json.loads, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\", dest=\"_output_paths\", type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = get_best_hyperparameters(**_parsed_args)\n\n_outputs = [_outputs]\n\n_output_serializers = [\n    _serialize_json,\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
          ],
          "image": "python:3.10"
        }
      }
    }
  },
  "pipelineInfo": { "name": "get-best-hyperparameters-op-test" },
  "root": {
    "dag": {
      "tasks": {
        "get-best-hyperparameters": {
          "cachingOptions": { "enableCache": true },
          "componentRef": { "name": "comp-get-best-hyperparameters" },
          "inputs": {
            "parameters": {
              "study_spec_metrics": {
                "runtimeValue": {
                  "constant": [{ "goal": 1.0, "metric_id": "accuracy" }]
                }
              },
              "trials": {
                "runtimeValue": {
                  "constant": [
                    "{\n \"id\": \"1\",\n \"state\": 4,\n \"parameters\": [\n {\n \"parameterId\": \"learning_rate\",\n \"value\": 0.03162277660168379\n },\n {\n \"parameterId\": \"momentum\",\n \"value\": 0.5\n },\n {\n \"parameterId\": \"num_neurons\",\n \"value\": 128.0\n }\n ],\n \"finalMeasurement\": {\n \"stepCount\": \"10\",\n \"metrics\": [\n {\n \"metricId\": \"accuracy\",\n \"value\": 0.734375\n }\n ]\n },\n \"startTime\": \"2021-12-10T00:41:57.675086142Z\",\n \"endTime\": \"2021-12-10T00:52:35Z\",\n \"name\": \"\",\n \"measurements\": [],\n \"clientId\": \"\",\n \"infeasibleReason\": \"\",\n \"customJob\": \"\"\n}"
                  ]
                }
              }
            }
          },
          "taskInfo": { "name": "get-best-hyperparameters" }
        }
      }
    }
  }
}
